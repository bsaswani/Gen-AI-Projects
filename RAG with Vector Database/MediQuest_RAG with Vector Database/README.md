# ğŸ’Š MediQuest â€“ RAG with Vector Database

# ğŸ“Œ Overview 

MediQuest is a Retrieval-Augmented Generation (RAG) system that combines the **LLaMA 3.2 â€“ 1B** model with a **FAISS vector database** for intelligent medical question answering.
The system retrieves relevant PubMed abstracts and generates grounded, context-aware responses powered by embeddings and retrieval pipelines.

# âš™ï¸ Workflow 

1ï¸âƒ£ Load and preprocess the **PubMedQA** dataset (first 500 samples).  
2ï¸âƒ£ Split and embed text using **BAAI/bge-small-en-v1.5** embeddings.  
3ï¸âƒ£ Store embeddings in a **FAISS vector index** for similarity-based retrieval.  
4ï¸âƒ£ Load the **LLaMA 3.2 â€“ 1B** model via Hugging Face Transformers.  
5ï¸âƒ£ Define the **RAG chain** combining retriever, context formatter, and response generator.  
6ï¸âƒ£ Query the system with medical questions to obtain factual, grounded answers.  

# ğŸ“Š Dataset  

- **Source**: Hugging Face â€“ PubMedQA (`pqa_labeled`)  
- **Format**: Question, Context, and Answer pairs  
- **Subset Used**: 500 records for efficient retrieval  

# ğŸ›  Technologies Used  

- Python  
- Hugging Face Transformers (**LLaMA 3.2 â€“ 1B**)  
- LangChain  
- FAISS Vector Database  
- Google Colab  
- Pandas, NumPy, Torch  

# ğŸš€ Usage  

1ï¸âƒ£ Open `MediQuest_RAG_with_Vector_Database.ipynb` in **Google Colab**.  
2ï¸âƒ£ Enter your **Hugging Face token** when prompted.  
3ï¸âƒ£ Run all cells to initialize embeddings, build the FAISS index, and start querying the RAG system.
